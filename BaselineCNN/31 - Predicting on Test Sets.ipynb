{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a186b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Jupyter Notebook full screen \n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
    "Tableau10 = {'blue':'#4E79A7', 'orange':'#F28E2B', 'red':'#E15759', 'teal':'#76B7B2', 'green':'#59A14F', \n",
    "             'yellow':'#EDC948', 'purple':'#B07AA1', 'pink':'#FF9DA7', 'brown':'#9C755F', 'gray':'#BAB0AC'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018a016c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Math manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Vizualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "# Image processing\n",
    "import cv2\n",
    "\n",
    "# Utilities\n",
    "import os\n",
    "import random\n",
    "import gc\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.image import img_to_array, load_img\n",
    "from keras.utils import to_categorical\n",
    "import codecs, json \n",
    "import re\n",
    "\n",
    "from albumentations import Compose\n",
    "import albumentations as A\n",
    "import random\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import optimizers\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "\n",
    "#utils\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "\n",
    "# Models\n",
    "from keras import applications\n",
    "from keras.optimizers import SGD, Adam\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f348fe94",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = \"/Users/megantabbutt/Desktop/Computer Science Classes/762_AdvancedDeepLearning/762_Project/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c6e61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "FLAG_DEBUG = False\n",
    "FLAG_GENERATE_TABLE = True\n",
    "FLAG_TRAIN_IN_PRELOAD = False\n",
    "\n",
    "img_height = 256 #- these should already be done in pre-processing \n",
    "img_width = 256 #- these should already be done in pre-processing \n",
    "img_channels = 1\n",
    "\n",
    "batch_size = 900"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49b1410",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names=['Human', 'Interact front', 'Interact lat', 'Interact vert', 'Crowded', \n",
    "             'Drink', 'Curiosity', 'Queue', 'Low visibility', 'Nothing']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c974f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_pointer_table (path_frames, path_labels): # MEGAN REFACTOR\n",
    "    pt_table = []\n",
    "    \n",
    "    label_file = open(path_labels)\n",
    "    label_data = json.load(label_file)\n",
    "    \n",
    "    for frame in os.listdir(path_frames):\n",
    "        if frame[-4:] == \".jpg\":\n",
    "            key = frame.split(\".\")[0]\n",
    "            pt_table.append([key, label_data[key]])\n",
    "        \n",
    "    return pt_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19742696",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_pointer_table():\n",
    "    pointer_table_path_test = path_labels_base + 'pointer_table_test.json'\n",
    "    pointer_table_shuffled_path_test = path_labels_base + 'pointer_table_shuffled_test.json'\n",
    "    if FLAG_DEBUG: print ('Number of files: ', len(list_of_videos))\n",
    "\n",
    "    if FLAG_GENERATE_TABLE:      \n",
    "        pt_table = generate_pointer_table(path_frames_test, path_labels)\n",
    "        json.dump(pt_table, codecs.open(pointer_table_path_test, 'w', encoding='utf-8'))\n",
    "        print('Test Pointer table saved')\n",
    "        random.shuffle(pt_table)\n",
    "        json.dump(pt_table, codecs.open(pointer_table_shuffled_path_test, 'w', encoding='utf-8'))\n",
    "        print('Test Shuffled pointer table saved')\n",
    "        pt_table_test = np.array(pt_table)\n",
    "\n",
    "    test_max_index = n_test\n",
    "    print(len(pt_table_test))\n",
    "\n",
    "    gc.collect()\n",
    "    \n",
    "    return pt_table_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e6f2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentation_test = A.Compose([\n",
    "    A.ToFloat(max_value=255)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a796254",
   "metadata": {},
   "outputs": [],
   "source": [
    "def frame_from_pointer (path, video, frame, verbose=False):\n",
    "    if verbose: print ('In '+path+'/'+str(video)+'.mp4' + ', taking frame ' + str(frame))\n",
    "    cap = cv2.VideoCapture(path+'/'+str(video)+'.mp4')\n",
    "    if (cap.isOpened()== False):\n",
    "        print(\"Error opening video file\") \n",
    "        return -1\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, frame-1)\n",
    "    ret, frame = cap.read() # Capture next frame\n",
    "    if ret==True:\n",
    "        cap.release()\n",
    "        return frame\n",
    "    else:\n",
    "        print(\"Error opening frame\") \n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a9090f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def frame_from_pointer(path, vidframe):\n",
    "    image = cv2.imread(path + vidframe + \".jpg\")\n",
    "    \n",
    "    if image.shape[2] > 1: # grayscale got saved as three copies of the same image in three channels so just take one TODO - MEGAN FIX\n",
    "        image, G2, G3 = cv2.split(image)\n",
    "        \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6149bac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_generator_lazy(pt_table, batch_size, augmentation, frame_path):\n",
    "    \n",
    "    while True:          # Select files (paths/indices) for the batch\n",
    "        pointer_batch = pt_table[np.random.choice(pt_table.shape[0], batch_size, replace=False), :]\n",
    "        batch_X = []\n",
    "        batch_y = []\n",
    "        \n",
    "        for pointer in pointer_batch:\n",
    "            frame = frame_from_pointer(path=frame_path, vidframe=pointer[0])\n",
    "            frame = frame.astype(np.float32) # MT added \n",
    "            #frame = augmentation(image=frame)['image']\n",
    "            #print(frame)\n",
    "            frame = frame.reshape(frame.shape[0], frame.shape[1], img_channels)\n",
    "            label = to_categorical(pointer[1], num_classes=10)\n",
    "        \n",
    "            batch_X.append(frame)\n",
    "            batch_y.append(label)\n",
    "             \n",
    "        # Return a tuple of (input,output) to feed the network          \n",
    "        batch_X = np.array(batch_X)\n",
    "        batch_y = np.array(batch_y)\n",
    "        yield(batch_X, batch_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a302a1",
   "metadata": {},
   "source": [
    "# Running the Data through predictions, and plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb48a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_frames_test = base + \"Data/Exp6_frames_unbalanced_256/test/\"\n",
    "\n",
    "path_labels_base = base + \"Data/Exp6_frames_unbalanced_256/labels_paper/\"  \n",
    "path_labels = path_labels_base + \"labels_paper_test.json\"\n",
    "\n",
    "model_path = base + \"ModelSave/Exp6_V1_model.h5\"\n",
    "acc_path = base + \"ModelSave/Exp6_V1_accuracies.json\"\n",
    "n_test = len(os.listdir(path_frames_test))\n",
    "\n",
    "write_data = False\n",
    "\n",
    "#______________________________________________________________________\n",
    "\n",
    "model = load_model(model_path) \n",
    "\n",
    "with open(path_labels) as fp:\n",
    "    truth_data = json.load(fp)\n",
    "    \n",
    "data_to_write = dict()\n",
    "\n",
    "for i, file in enumerate(os.listdir(path_frames_test)):\n",
    "    if file[0] == \".\":\n",
    "        continue\n",
    "    vid = file.split(\".\")[0]\n",
    "    \n",
    "    frame = cv2.imread(path_frames_test + file)\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
    "    down_points = (img_width, img_height)\n",
    "    frame = cv2.resize(frame, down_points, interpolation=cv2.INTER_CUBIC)\n",
    "    frame = np.reshape(frame, (1, 256, 256, 1))\n",
    "    prediction = model.predict(frame)\n",
    "\n",
    "    data_to_write[file] = list(prediction[0].astype(float))\n",
    "    \n",
    "if write_data:\n",
    "    file_out = base + \"Data/CNN_Predictions/\"\n",
    "\n",
    "    file_name = path_frames_test.split(\"/\")[-3] + \"_pipeline_predictions.json\"\n",
    "\n",
    "    with open(file_out + file_name, 'w') as fp:\n",
    "        json.dump(data_to_write, fp)\n",
    "    print(\"Written: \", len(data_to_write), \"  to   \", file_name)\n",
    "    print(file_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1299a948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For including 0 cases only:\n",
    "\n",
    "y_predicted = []\n",
    "y_truth = []\n",
    "\n",
    "for file in data_to_write:\n",
    "    if file[0] == \".\": continue\n",
    "    frame = file.split(\".\")[0]\n",
    "    #frame = file.split(\".\")[0].split(\"_\")[0] + \"_\" + file.split(\".\")[0].split(\"_\")[1]\n",
    "    y_predicted.append(np.argmax(data_to_write[file]))\n",
    "    \n",
    "for i, file in enumerate(os.listdir(path_frames_test)):\n",
    "    if file[0] == \".\": continue\n",
    "    info = file.split(\"_\")\n",
    "    y_truth.append(int(file.split(\"_\")[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7146f47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = []\n",
    "y_truth = []\n",
    "\n",
    "for file in data_to_write:\n",
    "    if file[0] == \".\": continue\n",
    "    frame = file.split(\".\")[0]\n",
    "    #frame = file.split(\".\")[0].split(\"_\")[0] + \"_\" + file.split(\".\")[0].split(\"_\")[1]\n",
    "    y_predicted.append(np.argmax(data_to_write[file]))\n",
    "    y_truth.append(truth_data[frame])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113618ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_data = False\n",
    "\n",
    "cm = confusion_matrix(y_truth, y_predicted)\n",
    "\n",
    "FP = cm.sum(axis=0) - np.diag(cm)  \n",
    "FN = cm.sum(axis=1) - np.diag(cm)\n",
    "TP = np.diag(cm)\n",
    "TN = cm.sum() - (FP + FN + TP)\n",
    "\n",
    "F1 = 2*TP / (2*TP + FP + FN)\n",
    "PREC = TP / (TP + FP)\n",
    "REC = TP / (TP + FN)\n",
    "\n",
    "stats_to_write = dict()\n",
    "stats_to_write[\"FP\"] = list(FP.astype(float))\n",
    "stats_to_write[\"FN\"] = list(FN.astype(float))\n",
    "stats_to_write[\"TP\"] = list(TP.astype(float))\n",
    "stats_to_write[\"TN\"] = list(TN.astype(float))\n",
    "\n",
    "if write_data:\n",
    "    file_out = base + \"Data/CNN_Predictions/\"\n",
    "\n",
    "    file_name = path_frames_test.split(\"/\")[-3] + \"_stats.json\"\n",
    "\n",
    "    with open(file_out + file_name, 'w') as fp:\n",
    "        json.dump(stats_to_write, fp)\n",
    "    print(\"Written: \", len(stats_to_write), \"  to   \", file_name)\n",
    "    print(file_out)\n",
    "\n",
    "print(FP)\n",
    "print(FN)\n",
    "print(TP)\n",
    "print(TN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289db986",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"precision, recall, Fscore, support\")\n",
    "sklearn.metrics.precision_recall_fscore_support(y_truth, y_predicted, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97d3762",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = 0 \n",
    "for i in range(cm.shape[0]):\n",
    "    corr += cm[i, i]\n",
    " \n",
    "print(\"Overall Accuracy:\")\n",
    "corr/ np.sum(np.sum(cm, axis=1, keepdims=True))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4a0d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exp = np.zeros(cm.shape)\n",
    "#for i in range(cm.shape[0]):\n",
    "#    exp[i, i] = (cm[i, i] / np.sum(cm, axis=1, keepdims=True)[i]) * np.max((cm * (np.ones(cm.shape) - np.identity(cm.shape[0]))))\n",
    "#cm_norm = exp - (cm * (np.ones(cm.shape) - np.identity(cm.shape[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f5009b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_norm = np.zeros(cm.shape)\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        cm_norm[i, j] = cm[i, j] / np.sum(cm, axis=1, keepdims=True)[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea75287f",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_data = True\n",
    "\n",
    "def plot_cm(labels_x, labels_y, title):\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    cax = ax.matshow(cm_norm, cmap=plt.cm.YlGnBu, alpha=.9, vmin=0, vmax=1.)\n",
    "    cbar = fig.colorbar(cax, fraction=0.045)\n",
    "    cbar.set_label(label='Occurance', size=18)\n",
    "    cbar.outline.set_edgecolor('white')\n",
    "    cbar.set_ticks([])\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            cm_sum = np.sum(cm, axis=1, keepdims=True)\n",
    "            cm_perc = cm / cm_sum.astype(float)\n",
    "            color = 'black'\n",
    "            if cm_norm[i, j] > .50: color = 'white'\n",
    "            if i == j:\n",
    "                ax.text(x=j, y=i-.2, s=\"{:.1%}\".format(cm_perc[i, j]), va='center', ha='center', size='large', c=color, fontweight='bold')\n",
    "                ax.text(x=j, y=i+.2, s=\"{}/{}\".format(cm[i, j], int(cm_sum[i])), va='center', ha='center', size='large', c=color)\n",
    "            else:\n",
    "                ax.text(x=j, y=i,s=\"{}\".format(cm[i, j]), c=color, va='center', ha='center', size='medium')\n",
    "\n",
    "    ax.tick_params(axis=\"x\", bottom=True, top=False, labelbottom=True, labeltop=False)\n",
    "    ax.set_xticklabels(labels=labels_x, rotation=30, fontsize='large')\n",
    "    ax.set_yticklabels(labels=labels_y, fontsize='large')\n",
    "    ax.spines['top'].set_visible(False), ax.spines['right'].set_visible(False), \n",
    "    ax.spines['bottom'].set_visible(False), ax.spines['left'].set_visible(False)\n",
    "    \n",
    "    plt.xlabel('Predicted', fontsize=18)\n",
    "    plt.ylabel('Actual', fontsize=18, )\n",
    "    plt.title(title, y=1.02, fontsize=18)\n",
    "    fig.tight_layout()\n",
    "    if write_data:\n",
    "        file_out = base + \"Data/CNN_Predictions/\"\n",
    "        file_name = path_frames_test.split(\"/\")[-3] + \"_confusionMatrix\"\n",
    "        plt.savefig(file_out+file_name, dpi=550, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "plot_cm(['', 'Group Interact.', 'Drinking', 'Waiting in Line'], \n",
    "       ['', 'Group Interact.', 'Drinking', 'Waiting in Line'], \n",
    "       title=\"Exp4: Cropped Images\")\n",
    "\n",
    "# ['', 'Nothing', 'Group Interact.', 'Drinking', 'Waiting in Line']\n",
    "# ['', 'Group Interact.', 'Drinking', 'Waiting in Line']\n",
    "# ['', 'Interact front', 'Interact lat', 'Interact vert', 'Crowded', 'Drink', 'Curiosity', 'Queue', 'Low visibility', 'Nothing']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b13bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_data = True\n",
    "\n",
    "with open(acc_path) as fp:\n",
    "    accuricies = json.load(fp)\n",
    "    \n",
    "acc = accuricies['acc']\n",
    "val_acc = accuricies['val_acc']\n",
    "loss = accuricies['loss']\n",
    "val_loss = accuricies['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "fig, axs = plt.subplots(figsize=(6, 4))\n",
    "axs.spines['top'].set_visible(False), axs.spines['right'].set_visible(False), \n",
    "axs.spines['bottom'].set_visible(True), axs.spines['left'].set_visible(True)\n",
    "\n",
    "axs.plot(epochs, acc, c=Tableau10['blue'], label='Training')\n",
    "axs.plot(epochs, val_acc, c=Tableau10['red'], label='Validation')\n",
    "axs.set_xlabel(\"Epochs\", fontsize=18)\n",
    "axs.set_ylabel(\"Accurarcy\", fontsize=18)\n",
    "axs.grid()\n",
    "\n",
    "axs.legend(loc=\"lower right\", fontsize=14)\n",
    "plt.title(\"Exp6: Cropped Images - Weak Supervision\", fontsize=16)\n",
    "fig.tight_layout()\n",
    "\n",
    "if write_data:\n",
    "    file_out = base + \"Data/CNN_Predictions/\"\n",
    "    file_name = path_frames_test.split(\"/\")[-3] + \"_accuracies\"\n",
    "    plt.savefig(file_out+file_name, dpi=550, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09264816",
   "metadata": {},
   "outputs": [],
   "source": [
    "#classes = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "\n",
    "#for cla in classes:\n",
    "#    correct = 0\n",
    "#    total = 0\n",
    "#    for key in data_to_write:\n",
    "#        vid_name = key.split(\".\")[0]\n",
    "#       if truth_data[vid_name] == cla:\n",
    "#            total += 1\n",
    "#            if truth_data[vid_name] == np.argmax(data_to_write[key]):\n",
    "#                correct += 1\n",
    "#                \n",
    "#    if total > 0:\n",
    "#        print(cla, total, correct/total)\n",
    "#    else:\n",
    "#        print(cla)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4478e9",
   "metadata": {},
   "source": [
    "# Prepping some stats info:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3369567",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = \"/Users/megantabbutt/Desktop/Computer Science Classes/762_AdvancedDeepLearning/762_Project/Data/CNN_Predictions/\"\n",
    "file_in = \"Exp3_frames_unbalanced_256_manual_A_stats.json\"\n",
    "\n",
    "with open(base + file_in) as fp:\n",
    "    stats = json.load(fp)\n",
    "    \n",
    "def get_acc_stats(FP, FN, TP, TN):\n",
    "    \n",
    "    if (TP + TN + FP + FN) == 0: ACC = np.nan\n",
    "    else: ACC = (TP + TN) / (TP + TN + FP + FN)\n",
    "    \n",
    "    if (2*TP + FP + FN) == 0: F1 = np.nan\n",
    "    else: F1 = 2*TP / (2*TP + FP + FN)\n",
    "    \n",
    "    if (TP + FP) == 0: PREC = np.nan\n",
    "    else: PREC = TP / (TP + FP)\n",
    "    \n",
    "    if (TP + FN) == 0: REC = np.nan\n",
    "    else: REC = TP / (TP + FN)\n",
    "    \n",
    "    return ACC, F1, PREC, REC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498db0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(stats['FP'])):\n",
    "    ACC, F1, PREC, REC = get_acc_stats(stats['FP'][i], stats['FN'][i], stats['TP'][i], stats['TN'][i])\n",
    "    print(\"{:.1%},\\t {:.1%},\\t {:.1%},\\t {:.1%}\".format(ACC, F1, PREC, REC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a453c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730d395a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa7f176",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras-CS762-env",
   "language": "python",
   "name": "keras-cs762-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
