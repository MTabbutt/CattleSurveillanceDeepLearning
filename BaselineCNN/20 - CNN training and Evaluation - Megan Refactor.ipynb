{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899c485d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Jupyter Notebook full screen \n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2b4948",
   "metadata": {},
   "source": [
    "## Notes: \n",
    "\n",
    "- Should have a set of inputs that are pre-processed to have training and testing sets in seperate dirs, at the resolution that you want (256) and already grayscale\n",
    "- Labels to accompany these should also be in the main directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96bb2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Math manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Vizualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "# Image processing\n",
    "import cv2\n",
    "\n",
    "# Utilities\n",
    "import os\n",
    "import random\n",
    "import gc\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.image import img_to_array, load_img\n",
    "from keras.utils import to_categorical\n",
    "import codecs, json \n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c326803",
   "metadata": {},
   "outputs": [],
   "source": [
    "from albumentations import Compose\n",
    "import albumentations as A\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488170b1",
   "metadata": {},
   "source": [
    "### Should be using the 256 reduced images in grayscale as input to this model to run on GPU so shouldn't need to resize of grayscale... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0895455",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Change these variables to your desired values\n",
    "img_height = 256 #- these should already be done in pre-processing \n",
    "img_width = 256 #- these should already be done in pre-processing \n",
    "img_channels = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a9e834",
   "metadata": {},
   "source": [
    "### Should be using the labels that come with the reduced training/testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1402f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the labels that are assigned by the paper\n",
    "path_labels_base = \"/Users/megantabbutt/Desktop/Computer Science Classes/762_AdvancedDeepLearning/762_Project/Data/Exp3_frames_unbalanced_256/labels_paper/\"  \n",
    "path_labels = path_labels_base + \"labels_paper.json\"\n",
    "\n",
    "# Training and testing data dir\n",
    "path_frames_train = \"/Users/megantabbutt/Desktop/Computer Science Classes/762_AdvancedDeepLearning/762_Project/Data/Exp3_frames_unbalanced_256/train/\"\n",
    "path_frames_test = \"/Users/megantabbutt/Desktop/Computer Science Classes/762_AdvancedDeepLearning/762_Project/Data/Exp3_frames_unbalanced_256/test/\"\n",
    "\n",
    "model_stable_path = './models/model.h5' # From where to load the CNN before training\n",
    "model_save_path = './models/model.h5' # Where to save the CNN after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25ba111",
   "metadata": {},
   "outputs": [],
   "source": [
    "#n=100000 # if you want to limit to a small subset of the data\n",
    "n_train = 1598\n",
    "n_test = 1000\n",
    "#test_size=0.1\n",
    "val_size = 0.2 #fraction of training size\n",
    "batch_size = 32\n",
    "epochs = 1000 # For how many epochs to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07193fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "FLAG_DEBUG = False\n",
    "FLAG_GENERATE_TABLE=True # If false: load a previously generated table - NO CODE IMPLEMENTED FOR FALSE TODO\n",
    "FLAG_TRAIN=True # If false: just load a model, do not retrain\n",
    "FLAG_TRAIN_IN_PRELOAD=False #if false: train with lazy loading (see details in Training Modes section) - NO CODE IMPLEMENTED FOR TRUE TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933cebc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names=['Human', 'Interaction frontal', 'Interaction lateral', 'Interaction vertical', 'Crowded', \n",
    "             'Drink', 'Curiosity', 'Queue', 'Low visibility', 'Nothing']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3602a52c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a3ab72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_pointer_table (path_frames, path_labels): # MEGAN REFACTOR\n",
    "    pt_table = []\n",
    "    \n",
    "    label_file = open(path_labels)\n",
    "    label_data = json.load(label_file)\n",
    "    \n",
    "    for frame in os.listdir(path_frames):\n",
    "        if frame[-4:] == \".jpg\":\n",
    "            key = frame.split(\".\")[0]\n",
    "            pt_table.append([key, label_data[key]])\n",
    "        \n",
    "    return pt_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0615c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the pointer table for testing and training images\n",
    "# path_labels, path_frames_train, path_frames_test\n",
    "\n",
    "#list_of_videos = [path_labels + i for i in sorted(os.listdir(path_labels))]\n",
    "pointer_table_path_test = path_labels_base + 'pointer_table_test.json'\n",
    "pointer_table_path_train = path_labels_base + 'pointer_table_train.json'\n",
    "pointer_table_shuffled_path_test = path_labels_base + 'pointer_table_shuffled_test.json'\n",
    "pointer_table_shuffled_path_train = path_labels_base + 'pointer_table_shuffled_train.json'\n",
    "if FLAG_DEBUG: print ('Number of files: ', len(list_of_videos))\n",
    "    \n",
    "if FLAG_GENERATE_TABLE:   \n",
    "    pt_table = generate_pointer_table(path_frames_train, path_labels)\n",
    "    json.dump(pt_table, codecs.open(pointer_table_path_train, 'w', encoding='utf-8'))\n",
    "    print('Train Pointer table saved')\n",
    "    random.shuffle(pt_table)\n",
    "    json.dump(pt_table, codecs.open(pointer_table_shuffled_path_train, 'w', encoding='utf-8'))\n",
    "    print('Train Shuffled pointer table saved')\n",
    "    pt_table_train_full = np.array(pt_table)\n",
    "    \n",
    "    \n",
    "    pt_table = generate_pointer_table(path_frames_test, path_labels)\n",
    "    json.dump(pt_table, codecs.open(pointer_table_path_test, 'w', encoding='utf-8'))\n",
    "    print('Test Pointer table saved')\n",
    "    random.shuffle(pt_table)\n",
    "    json.dump(pt_table, codecs.open(pointer_table_shuffled_path_test, 'w', encoding='utf-8'))\n",
    "    print('Test Shuffled pointer table saved')\n",
    "    pt_table_test = np.array(pt_table)\n",
    "\n",
    "\n",
    "train_max_index = int(n_train*(1 - val_size))\n",
    "val_max_index = int(train_max_index + n_train*val_size)\n",
    "test_max_index = n_test\n",
    "\n",
    "pt_table_train = pt_table_train_full[0:train_max_index]\n",
    "pt_table_val = pt_table_train_full[train_max_index:val_max_index]\n",
    "\n",
    "\n",
    "if FLAG_DEBUG:\n",
    "    print ('Train index = ',0,':', train_max_index)\n",
    "    print ('Val index   = ', train_max_index,':', val_max_index)\n",
    "    print ('Test index  = ', val_max_index,':', test_max_index)\n",
    "\n",
    "\n",
    "#del list_of_videos, pt_table\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4dd9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pt_table_train), len(pt_table_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a4cd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shouldn't need to do this... \n",
    "\n",
    "#def preprocess_frame(frame):\n",
    "#    if type(frame) != int and len(frame.shape)>1:\n",
    "#        frame = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY) # convert to greyscale\n",
    "#    frame = cv2.resize (frame, (img_width, img_height), interpolation=cv2.INTER_CUBIC) # rezize\n",
    "#    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1205550",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentation_train = A.Compose([\n",
    "    A.RandomContrast(limit=0.3, p=0.5),\n",
    "    A.RandomGamma(gamma_limit=(70, 130), p=0.5),\n",
    "    A.RandomBrightness(limit=0.6, p=0.5),\n",
    "    A.ShiftScaleRotate(\n",
    "        shift_limit=0.05, \n",
    "        scale_limit=0.05, \n",
    "        rotate_limit=10, \n",
    "        border_mode=cv2.BORDER_CONSTANT, \n",
    "        p=0.5), \n",
    "    A.ToFloat(max_value=255),\n",
    "])\n",
    "\n",
    "augmentation_test = A.Compose([\n",
    "    A.ToFloat(max_value=255)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e35134",
   "metadata": {},
   "outputs": [],
   "source": [
    "def frame_from_pointer (path, video, frame, verbose=False):\n",
    "    if verbose: print ('In '+path+'/'+str(video)+'.mp4' + ', taking frame ' + str(frame))\n",
    "    cap = cv2.VideoCapture(path+'/'+str(video)+'.mp4')\n",
    "    if (cap.isOpened()== False):\n",
    "        print(\"Error opening video file\") \n",
    "        return -1\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, frame-1)\n",
    "    ret, frame = cap.read() # Capture next frame\n",
    "    if ret==True:\n",
    "        cap.release()\n",
    "        return frame\n",
    "    else:\n",
    "        print(\"Error opening frame\") \n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0d80b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def frame_from_pointer(path, vidframe):\n",
    "    image = cv2.imread(path + vidframe + \".jpg\")\n",
    "    \n",
    "    if image.shape[2] > 1: # grayscale got saved as three copies of the same image in three channels so just take one TODO - MEGAN FIX\n",
    "        image, G2, G3 = cv2.split(image)\n",
    "        \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b75c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_generator_lazy(pt_table, batch_size, augmentation, frame_path):\n",
    "    \n",
    "    while True:          # Select files (paths/indices) for the batch\n",
    "        pointer_batch = pt_table[np.random.choice(pt_table.shape[0], batch_size, replace=False), :]\n",
    "        batch_X = []\n",
    "        batch_y = []\n",
    "        \n",
    "        for pointer in pointer_batch:\n",
    "            frame = frame_from_pointer(path=frame_path, vidframe=pointer[0])\n",
    "            #print(type(frame))\n",
    "            #if type(frame) != int: print(frame.shape)\n",
    "            #frame = preprocess_frame(frame)\n",
    "            frame = frame.astype(np.float32) # MT added \n",
    "            frame = augmentation(image=frame)['image']\n",
    "            frame = frame.reshape(frame.shape[0], frame.shape[1], img_channels)\n",
    "            label = to_categorical(pointer[1], num_classes=10)\n",
    "        \n",
    "            batch_X.append(frame)\n",
    "            batch_y.append(label)\n",
    "             \n",
    "        # Return a tuple of (input,output) to feed the network          \n",
    "        batch_X = np.array(batch_X)\n",
    "        batch_y = np.array(batch_y)\n",
    "        yield(batch_X, batch_y)\n",
    "\n",
    "        \n",
    "if not FLAG_TRAIN_IN_PRELOAD:\n",
    "    #get the length of the train and validation data\n",
    "    ntrain = len(pt_table_train)\n",
    "    nval = len(pt_table_val)\n",
    "\n",
    "    train_generator = image_generator_lazy(pt_table_train, batch_size=batch_size, augmentation=augmentation_train, frame_path=path_frames_train)\n",
    "    val_generator = image_generator_lazy(pt_table_val, batch_size=batch_size, augmentation=augmentation_test, frame_path=path_frames_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d716c8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import optimizers\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "\n",
    "#utils\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "\n",
    "# Models\n",
    "from keras import applications\n",
    "from keras.optimizers import SGD, Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70afcbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(img_height, img_width, img_channels)),\n",
    "    MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
    "\n",
    "    Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
    "\n",
    "    Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
    "\n",
    "\n",
    "    Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
    "\n",
    "    Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
    "\n",
    "\n",
    "    Conv2D(512, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
    "\n",
    "    Conv2D(512, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "model.compile(loss=keras.losses.categorical_crossentropy, optimizer='adam', metrics=['accuracy']) \n",
    "    \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7dccb09",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#model = load_model(model_stable_path) # load last stable model (can be commented to train from scrach)\n",
    "initial_epoch=0 # MT added\n",
    "    \n",
    "if FLAG_TRAIN: \n",
    "    #callback_es = EarlyStopping(monitor='val_acc', mode='max', verbose=1, patience=20) #paper used\n",
    "    callback_es = EarlyStopping(monitor='val_acc', mode='max', verbose=1, patience=20)\n",
    "    callback_cp = ModelCheckpoint(model_save_path, monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
    "\n",
    "    history = model.fit_generator(train_generator,\n",
    "                                  steps_per_epoch=ntrain // batch_size,\n",
    "                                  epochs=initial_epoch+epochs,\n",
    "                                  initial_epoch=initial_epoch,\n",
    "                                  validation_data=val_generator,\n",
    "                                  validation_steps=nval // batch_size,\n",
    "                                  verbose=0, \n",
    "                                  callbacks=[TQDMNotebookCallback(), callback_es, callback_cp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05682e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "#Train and validation acc\n",
    "plt.grid(True)\n",
    "plt.plot(epochs, acc, 'b', label='Training accurarcy')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation accurarcy')\n",
    "plt.title('Training and Validation accurarcy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "\n",
    "#Train and validation loss\n",
    "plt.grid(True)\n",
    "plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and Validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b1df72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if FLAG_TRAIN:\n",
    "model = load_model(model_save_path) # load the best model saved in training phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c729151b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a975257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The test should be done with pre loading, so I will take directly from the generator \n",
    "test_generator = image_generator_lazy(pt_table_test, batch_size=batch_size, augmentation=augmentation_test, frame_path=path_frames_test)\n",
    "\n",
    "X_test = []\n",
    "y_test = []\n",
    "predictions = []\n",
    "for i in range(0, int(len(pt_table_test)/batch_size)):\n",
    "    X_batch, y_batch = next(test_generator)\n",
    "    predictions_batch = model.predict_on_batch(X_batch)\n",
    "    X_test.extend(X_batch)\n",
    "    y_test.extend(y_batch)\n",
    "    predictions.extend(predictions_batch)\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "predictions = np.array(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2c5607",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, acc = model.evaluate(X_test, y_test)\n",
    "print('Test acc:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a066f574",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c6181a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_table_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f12da02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Brief: evaluate the 'accuracy' as considering a hit if the true label is in one of the three most confident predictions\n",
    "# Return: acc\n",
    "def evaluate_minority_acc (y, y_hat):\n",
    "    acc = 0\n",
    "    for i in range(0, len(y), 1):\n",
    "        pred_array = []\n",
    "        pred_array.append(np.where(y_hat[i] == sorted(y_hat[i])[-1])[0][0])\n",
    "        pred_array.append(np.where(y_hat[i] == sorted(y_hat[i])[-2])[0][0])\n",
    "        pred_array.append(np.where(y_hat[i] == sorted(y_hat[i])[-3])[0][0])\n",
    "        if np.argmax(y[i]) in pred_array: acc += 1\n",
    "    return acc/len (y)\n",
    "    \n",
    "    \n",
    "evaluate_minority_acc(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d7714a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Brief: plot the image with the predicted label, confidence and real label\n",
    "def plot_image(i, prediction, true_label, img):\n",
    "    plt.grid(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "    plt.imshow(img.reshape(img.shape[0], img.shape[1]))\n",
    "\n",
    "    if np.argmax(prediction) == np.argmax(true_label):\n",
    "        color = 'blue'\n",
    "    else:\n",
    "        color = 'red'\n",
    "\n",
    "    plt.xlabel(\"{}) {}, {:2.0f}% \\n({})\".format(\n",
    "        i,\n",
    "        label_names[np.argmax(prediction)],\n",
    "        100*np.max(prediction),\n",
    "        label_names[np.argmax(true_label)]), color=color)\n",
    "\n",
    "# Brief: plot a bar graph with the probability of each predicted class\n",
    "def plot_value_array(prediction, true_label):\n",
    "    plt.grid(False)\n",
    "    plt.xticks(range(10))\n",
    "    thisplot = plt.bar(range(10), prediction, color=\"#777777\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37a11a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aeee3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the first X test images, their predicted labels, and the true labels.\n",
    "# Color correct predictions in blue and incorrect predictions in red.\n",
    "\n",
    "FLAG_DEBUG = True\n",
    "\n",
    "if FLAG_DEBUG:\n",
    "    num_rows = 160\n",
    "    num_cols = 1\n",
    "    num_images = num_rows*num_cols\n",
    "    plt.figure(figsize=(7, 4*num_rows))\n",
    "    for i in range(num_images):\n",
    "        plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
    "        plot_image(i, predictions[i], y_test[i], X_test[i])\n",
    "        plt.subplot(num_rows, 2*num_cols, 2*i+2)\n",
    "        plot_value_array(predictions[i],  y_test[i])\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0732c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_cm(y_true, y_pred, figsize=(10,10)):\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=np.unique(y_true))\n",
    "    cm_sum = np.sum(cm, axis=1, keepdims=True)\n",
    "    cm_perc = cm / cm_sum.astype(float) * 100\n",
    "    annot = np.empty_like(cm).astype(str)\n",
    "    nrows, ncols = cm.shape\n",
    "    for i in range(nrows):\n",
    "        for j in range(ncols):\n",
    "            c = cm[i, j]\n",
    "            p = cm_perc[i, j]\n",
    "            if i == j:\n",
    "                s = cm_sum[i]\n",
    "                annot[i, j] = '%.1f%%\\n%d/%d' % (p, c, s)\n",
    "            elif c == 0:\n",
    "                annot[i, j] = ''\n",
    "            else:\n",
    "                annot[i, j] = '%.1f%%\\n%d' % (p, c)\n",
    "    cm = pd.DataFrame(cm, index=np.unique(y_true), columns=np.unique(y_true))\n",
    "    cm.index.name = 'Actual'\n",
    "    cm.columns.name = 'Predicted'\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    sns.heatmap(cm, cmap= \"YlGnBu\", annot=annot, fmt='', ax=ax, linewidths=.5)\n",
    "\n",
    "plot_cm(np.array([np.argmax(xi) for xi in y_test]), np.array([np.argmax(xi) for xi in predictions]))\n",
    "_n=0\n",
    "for i in label_names:\n",
    "    print('Class ' + str(_n) + ': ' + i)\n",
    "    _n+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2c1e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sklearn.metrics as metrics\n",
    "#print(metrics.classification_report(np.array([np.argmax(xi) for xi in y_test]), np.array([np.argmax(xi) for xi in predictions]), target_names=label_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43812645",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf95db1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27f50dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras-CS762-env",
   "language": "python",
   "name": "keras-cs762-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
