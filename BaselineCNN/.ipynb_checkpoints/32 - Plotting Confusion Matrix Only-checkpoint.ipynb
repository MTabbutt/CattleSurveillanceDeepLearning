{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c041c411",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make Jupyter Notebook full screen \n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
    "Tableau10 = {'blue':'#4E79A7', 'orange':'#F28E2B', 'red':'#E15759', 'teal':'#76B7B2', 'green':'#59A14F', \n",
    "             'yellow':'#EDC948', 'purple':'#B07AA1', 'pink':'#FF9DA7', 'brown':'#9C755F', 'gray':'#BAB0AC'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbffe8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = \"/Users/megantabbutt/Desktop/Computer Science Classes/762_AdvancedDeepLearning/762_Project/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8f9b3ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/opt/anaconda3/envs/keras-CS762-env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/anaconda3/envs/keras-CS762-env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/anaconda3/envs/keras-CS762-env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/anaconda3/envs/keras-CS762-env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/anaconda3/envs/keras-CS762-env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/anaconda3/envs/keras-CS762-env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/opt/anaconda3/envs/keras-CS762-env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/anaconda3/envs/keras-CS762-env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/anaconda3/envs/keras-CS762-env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/anaconda3/envs/keras-CS762-env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/anaconda3/envs/keras-CS762-env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/anaconda3/envs/keras-CS762-env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# Math manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Vizualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "# Image processing\n",
    "import cv2\n",
    "\n",
    "# Utilities\n",
    "import os\n",
    "import random\n",
    "import gc\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.image import img_to_array, load_img\n",
    "from keras.utils import to_categorical\n",
    "import codecs, json \n",
    "import re\n",
    "\n",
    "from albumentations import Compose\n",
    "import albumentations as A\n",
    "import random\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import optimizers\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "\n",
    "#utils\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "\n",
    "# Models\n",
    "from keras import applications\n",
    "from keras.optimizers import SGD, Adam\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "594a6129",
   "metadata": {},
   "outputs": [],
   "source": [
    "FLAG_DEBUG = False\n",
    "FLAG_GENERATE_TABLE = True\n",
    "FLAG_TRAIN_IN_PRELOAD = False\n",
    "\n",
    "img_height = 256 #- these should already be done in pre-processing \n",
    "img_width = 256 #- these should already be done in pre-processing \n",
    "img_channels = 1\n",
    "\n",
    "batch_size = 900"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbea049c",
   "metadata": {},
   "source": [
    "## Weak Supervision Cropped Results Comparison:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2fe411d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_frames_test = base + \"Data/Exp6_frames_unbalanced_256/test/\"\n",
    "\n",
    "path_labels_base = base + \"Data/Exp6_frames_unbalanced_256/labels_paper/\"  \n",
    "path_labels = path_labels_base + \"labels_paper_test.json\"\n",
    "\n",
    "model_path = base + \"ModelSave/Exp6_V1_model.h5\"\n",
    "acc_path = base + \"ModelSave/Exp6_V1_accuracies.json\"\n",
    "n_test = len(os.listdir(path_frames_test))\n",
    "\n",
    "#______________________________________________________________________\n",
    "\n",
    "model = load_model(model_path) \n",
    "\n",
    "with open(path_labels) as fp:\n",
    "    truth_data = json.load(fp)\n",
    "    \n",
    "data_to_write_6 = dict()\n",
    "\n",
    "for i, file in enumerate(os.listdir(path_frames_test)):\n",
    "    if file[0] == \".\":\n",
    "        continue\n",
    "    vid = file.split(\".\")[0]\n",
    "    \n",
    "    frame = cv2.imread(path_frames_test + file)\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
    "    down_points = (img_width, img_height)\n",
    "    frame = cv2.resize(frame, down_points, interpolation=cv2.INTER_CUBIC)\n",
    "    frame = np.reshape(frame, (1, 256, 256, 1))\n",
    "    prediction = model.predict(frame)\n",
    "\n",
    "    data_to_write_6[file] = list(prediction[0].astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b26f8aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For including 0 cases only:\n",
    "\n",
    "y_predicted_6 = []\n",
    "y_truth_6 = []\n",
    "\n",
    "for file in data_to_write_6:\n",
    "    if file[0] == \".\": continue\n",
    "    frame = file.split(\".\")[0]\n",
    "    #frame = file.split(\".\")[0].split(\"_\")[0] + \"_\" + file.split(\".\")[0].split(\"_\")[1]\n",
    "    y_predicted_6.append(np.argmax(data_to_write_6[file]))\n",
    "    \n",
    "for i, file in enumerate(os.listdir(path_frames_test)):\n",
    "    if file[0] == \".\": continue\n",
    "    info = file.split(\"_\")\n",
    "    y_truth_6.append(int(file.split(\"_\")[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ca339f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_frames_test = base + \"Data/Exp4_frames_unbalanced_256/test_manual_V2/\"\n",
    "\n",
    "path_labels_base = base + \"Data/Exp4_frames_unbalanced_256/labels_paper/\"  \n",
    "path_labels = path_labels_base + \"labels_paper.json\"\n",
    "\n",
    "model_path = base + \"ModelSave/Exp4_V1_model.h5\"\n",
    "acc_path = base + \"ModelSave/Exp4_V1_accuracies.json\"\n",
    "n_test = len(os.listdir(path_frames_test))\n",
    "\n",
    "#______________________________________________________________________\n",
    "\n",
    "model = load_model(model_path) \n",
    "\n",
    "with open(path_labels) as fp:\n",
    "    truth_data = json.load(fp)\n",
    "    \n",
    "data_to_write_4 = dict()\n",
    "\n",
    "for i, file in enumerate(os.listdir(path_frames_test)):\n",
    "    if file[0] == \".\":\n",
    "        continue\n",
    "    vid = file.split(\".\")[0]\n",
    "    \n",
    "    frame = cv2.imread(path_frames_test + file)\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
    "    down_points = (img_width, img_height)\n",
    "    frame = cv2.resize(frame, down_points, interpolation=cv2.INTER_CUBIC)\n",
    "    frame = np.reshape(frame, (1, 256, 256, 1))\n",
    "    prediction = model.predict(frame)\n",
    "\n",
    "    data_to_write_4[file] = list(prediction[0].astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d1b2c6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For including 0 cases only:\n",
    "\n",
    "y_predicted_4 = []\n",
    "y_truth_4 = []\n",
    "\n",
    "for file in data_to_write_4:\n",
    "    if file[0] == \".\": continue\n",
    "    frame = file.split(\".\")[0]\n",
    "    #frame = file.split(\".\")[0].split(\"_\")[0] + \"_\" + file.split(\".\")[0].split(\"_\")[1]\n",
    "    y_predicted_4.append(np.argmax(data_to_write_4[file]))\n",
    "    \n",
    "for i, file in enumerate(os.listdir(path_frames_test)):\n",
    "    if file[0] == \".\": continue\n",
    "    info = file.split(\"_\")\n",
    "    y_truth_4.append(int(file.split(\"_\")[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3755481b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 [285]\n",
      "125 [285]\n",
      "53 [285]\n",
      "95 [285]\n",
      "5 [281]\n",
      "193 [281]\n",
      "21 [281]\n",
      "62 [281]\n",
      "2 [189]\n",
      "15 [189]\n",
      "163 [189]\n",
      "9 [189]\n",
      "10 [335]\n",
      "54 [335]\n",
      "13 [335]\n",
      "258 [335]\n"
     ]
    }
   ],
   "source": [
    "cm_6 = confusion_matrix(y_truth_6, y_predicted_6)\n",
    "cm_norm_6 = np.zeros(cm_6.shape)\n",
    "for i in range(cm_6.shape[0]):\n",
    "    for j in range(cm_6.shape[1]):\n",
    "        print(cm_6[i, j], np.sum(cm_6, axis=1, keepdims=True)[i])\n",
    "        cm_norm_6[i, j] = cm_6[i, j] / np.sum(cm_6, axis=1, keepdims=True)[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2d500b9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.04210526, 0.43859649, 0.18596491, 0.33333333],\n",
       "       [0.01779359, 0.68683274, 0.0747331 , 0.22064057],\n",
       "       [0.01058201, 0.07936508, 0.86243386, 0.04761905],\n",
       "       [0.02985075, 0.16119403, 0.03880597, 0.77014925]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_norm_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63db97e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras-CS762-env",
   "language": "python",
   "name": "keras-cs762-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
