{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a186b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Jupyter Notebook full screen \n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018a016c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Math manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Vizualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "# Image processing\n",
    "import cv2\n",
    "\n",
    "# Utilities\n",
    "import os\n",
    "import random\n",
    "import gc\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.image import img_to_array, load_img\n",
    "from keras.utils import to_categorical\n",
    "import codecs, json \n",
    "import re\n",
    "\n",
    "from albumentations import Compose\n",
    "import albumentations as A\n",
    "import random\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import optimizers\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "\n",
    "#utils\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "\n",
    "# Models\n",
    "from keras import applications\n",
    "from keras.optimizers import SGD, Adam\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f348fe94",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = \"/Users/megantabbutt/Desktop/Computer Science Classes/762_AdvancedDeepLearning/762_Project/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c6e61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "FLAG_DEBUG = False\n",
    "FLAG_GENERATE_TABLE = True\n",
    "FLAG_TRAIN_IN_PRELOAD = False\n",
    "\n",
    "img_height = 256 #- these should already be done in pre-processing \n",
    "img_width = 256 #- these should already be done in pre-processing \n",
    "img_channels = 1\n",
    "\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49b1410",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names=['Human', 'Interact front', 'Interact lat', 'Interact vert', 'Crowded', \n",
    "             'Drink', 'Curiosity', 'Queue', 'Low visibility', 'Nothing']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c974f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_pointer_table (path_frames, path_labels): # MEGAN REFACTOR\n",
    "    pt_table = []\n",
    "    \n",
    "    label_file = open(path_labels)\n",
    "    label_data = json.load(label_file)\n",
    "    \n",
    "    for frame in os.listdir(path_frames):\n",
    "        if frame[-4:] == \".jpg\":\n",
    "            key = frame.split(\".\")[0]\n",
    "            pt_table.append([key, label_data[key]])\n",
    "        \n",
    "    return pt_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19742696",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_pointer_table():\n",
    "    pointer_table_path_test = path_labels_base + 'pointer_table_test.json'\n",
    "    pointer_table_shuffled_path_test = path_labels_base + 'pointer_table_shuffled_test.json'\n",
    "    if FLAG_DEBUG: print ('Number of files: ', len(list_of_videos))\n",
    "\n",
    "    if FLAG_GENERATE_TABLE:      \n",
    "        pt_table = generate_pointer_table(path_frames_test, path_labels)\n",
    "        json.dump(pt_table, codecs.open(pointer_table_path_test, 'w', encoding='utf-8'))\n",
    "        print('Test Pointer table saved')\n",
    "        random.shuffle(pt_table)\n",
    "        json.dump(pt_table, codecs.open(pointer_table_shuffled_path_test, 'w', encoding='utf-8'))\n",
    "        print('Test Shuffled pointer table saved')\n",
    "        pt_table_test = np.array(pt_table)\n",
    "\n",
    "    test_max_index = n_test\n",
    "    print(len(pt_table_test))\n",
    "\n",
    "    gc.collect()\n",
    "    \n",
    "    return pt_table_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e6f2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentation_train = A.Compose([\n",
    "    A.RandomContrast(limit=0.3, p=0.5),\n",
    "    A.RandomGamma(gamma_limit=(70, 130), p=0.5),\n",
    "    A.RandomBrightness(limit=0.6, p=0.5),\n",
    "    A.ShiftScaleRotate(\n",
    "        shift_limit=0.05, \n",
    "        scale_limit=0.05, \n",
    "        rotate_limit=10, \n",
    "        border_mode=cv2.BORDER_CONSTANT, \n",
    "        p=0.5), \n",
    "    A.ToFloat(max_value=255),\n",
    "])\n",
    "\n",
    "augmentation_test = A.Compose([\n",
    "    A.ToFloat(max_value=255)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a796254",
   "metadata": {},
   "outputs": [],
   "source": [
    "def frame_from_pointer (path, video, frame, verbose=False):\n",
    "    if verbose: print ('In '+path+'/'+str(video)+'.mp4' + ', taking frame ' + str(frame))\n",
    "    cap = cv2.VideoCapture(path+'/'+str(video)+'.mp4')\n",
    "    if (cap.isOpened()== False):\n",
    "        print(\"Error opening video file\") \n",
    "        return -1\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, frame-1)\n",
    "    ret, frame = cap.read() # Capture next frame\n",
    "    if ret==True:\n",
    "        cap.release()\n",
    "        return frame\n",
    "    else:\n",
    "        print(\"Error opening frame\") \n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a9090f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def frame_from_pointer(path, vidframe):\n",
    "    image = cv2.imread(path + vidframe + \".jpg\")\n",
    "    \n",
    "    if image.shape[2] > 1: # grayscale got saved as three copies of the same image in three channels so just take one TODO - MEGAN FIX\n",
    "        image, G2, G3 = cv2.split(image)\n",
    "        \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6149bac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_generator_lazy(pt_table, batch_size, augmentation, frame_path):\n",
    "    \n",
    "    while True:          # Select files (paths/indices) for the batch\n",
    "        pointer_batch = pt_table[np.random.choice(pt_table.shape[0], batch_size, replace=False), :]\n",
    "        batch_X = []\n",
    "        batch_y = []\n",
    "        \n",
    "        for pointer in pointer_batch:\n",
    "            frame = frame_from_pointer(path=frame_path, vidframe=pointer[0])\n",
    "            frame = frame.astype(np.float32) # MT added \n",
    "            frame = augmentation(image=frame)['image']\n",
    "            frame = frame.reshape(frame.shape[0], frame.shape[1], img_channels)\n",
    "            label = to_categorical(pointer[1], num_classes=10)\n",
    "        \n",
    "            batch_X.append(frame)\n",
    "            batch_y.append(label)\n",
    "             \n",
    "        # Return a tuple of (input,output) to feed the network          \n",
    "        batch_X = np.array(batch_X)\n",
    "        batch_y = np.array(batch_y)\n",
    "        yield(batch_X, batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc202da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cm(y_true, y_pred, labels_x, labels_y, figsize=(10,10)):\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=np.unique(y_true))\n",
    "    cm_sum = np.sum(cm, axis=1, keepdims=True)\n",
    "    cm_perc = cm / cm_sum.astype(float) * 100\n",
    "    annot = np.empty_like(cm).astype(str)\n",
    "    nrows, ncols = cm.shape\n",
    "    for i in range(nrows):\n",
    "        for j in range(ncols):\n",
    "            c = cm[i, j]\n",
    "            p = cm_perc[i, j]\n",
    "            if i == j:\n",
    "                s = cm_sum[i]\n",
    "                annot[i, j] = '%.1f%%\\n%d/%d' % (p, c, s)\n",
    "            elif c == 0:\n",
    "                annot[i, j] = ''\n",
    "            else:\n",
    "                annot[i, j] = '%.1f%%\\n%d' % (p, c)\n",
    "    cm = pd.DataFrame(cm, index=np.unique(y_true), columns=np.unique(y_true))\n",
    "    cm.index.name = 'Actual'\n",
    "    cm.columns.name = 'Predicted'\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    sns.heatmap(cm, cmap= \"YlGnBu\", annot=annot, fmt='', ax=ax, linewidths=.5, xticklabels=labels_x, yticklabels=labels_y)\n",
    "    ax.tick_params(axis='x', rotation=+25)\n",
    "    ax.tick_params(axis='y', rotation=0)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a302a1",
   "metadata": {},
   "source": [
    "# 1. Unbalanced Video Data from Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f99bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_frames_test = base + \"Data/Exp1_frames_unbalanced_256/test/\"\n",
    "\n",
    "path_labels_base = base + \"Data/Exp1_frames_unbalanced_256/labels_paper/\"  \n",
    "path_labels = path_labels_base + \"labels_paper.json\"\n",
    "\n",
    "model_path = base + \"ModelSave/Exp1_V2_model.h5\"\n",
    "acc_path = base + \"ModelSave/Exp1_V2_accuracies.json\"\n",
    "n_test = len(os.listdir(path_frames_test))\n",
    "n_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8209115e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_table_test = do_pointer_table()\n",
    "\n",
    "model = load_model(model_path) # load the best model saved in training phase\n",
    "\n",
    "# Make predictions based on the test images\n",
    "test_generator = image_generator_lazy(pt_table_test, batch_size=batch_size, augmentation=augmentation_test, frame_path=path_frames_test)\n",
    "\n",
    "X_test = []\n",
    "y_test = []\n",
    "predictions = []\n",
    "for i in range(0, int(len(pt_table_test)/batch_size)):\n",
    "    X_batch, y_batch = next(test_generator)\n",
    "    predictions_batch = model.predict_on_batch(X_batch)\n",
    "    X_test.extend(X_batch)\n",
    "    y_test.extend(y_batch)\n",
    "    predictions.extend(predictions_batch)\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "predictions = np.array(predictions)\n",
    "\n",
    "_, acc = model.evaluate(X_test, y_test)\n",
    "print('Test acc:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142382df",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)\n",
    "np.array(predictions).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2cdfcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_singleval = np.array([np.argmax(xi) for xi in predictions])\n",
    "y_true_singleval = np.array([np.argmax(xi) for xi in y_test])\n",
    "\n",
    "cm = confusion_matrix(y_true_singleval, y_predict_singleval)\n",
    "\n",
    "FP = cm.sum(axis=0) - np.diag(cm)  \n",
    "FN = cm.sum(axis=1) - np.diag(cm)\n",
    "TP = np.diag(cm)\n",
    "TN = cm.sum() - (FP + FN + TP)\n",
    "\n",
    "F1 = 2*TP / (2*TP + FP + FN)\n",
    "PREC = TP / (TP + FP)\n",
    "REC = TP / (TP + FN)\n",
    "\n",
    "FP, FN, TP, TN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa69c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(PREC[0], PREC[-1])\n",
    "print(REC[0], REC[-1])\n",
    "print(F1[0], F1[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78dbba6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cm(np.array([np.argmax(xi) for xi in y_test]), np.array([np.argmax(xi) for xi in predictions]), \n",
    "        label_names[1:], label_names[1:], figsize=(9, 9))\n",
    "_n=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9bed62",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path_labels_base + 'pointer_table_shuffled_test.json') as fp:\n",
    "    shuffled_test = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9a95f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras-CS762-env",
   "language": "python",
   "name": "keras-cs762-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
