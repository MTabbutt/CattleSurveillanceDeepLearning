{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Jupyter Notebook full screen \n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Change these variables to your desired values\n",
    "img_height = 256\n",
    "img_width = 256\n",
    "img_channels = 1\n",
    "    \n",
    "path_labels = \"/Users/megantabbutt/Desktop/Computer Science Classes/762_AdvancedDeepLearning/\\\n",
    "762_Project/Codes/Paper_codes/labels/\"  # Where the labels are saved   \n",
    "path_videos = \"/Users/megantabbutt/Desktop/Computer Science Classes/762_AdvancedDeepLearning/\\\n",
    "762_Project/Codes/Paper_codes/video data_save\" # Where the videos are saved \n",
    "model_stable_path = './models/model.h5' # From where to load the CNN before training\n",
    "model_save_path = './models/model.h5' # Where to save the CNN after training\n",
    "\n",
    "#n=100000 # if you want to limit to a small subset of the data\n",
    "#n=1000\n",
    "n=300\n",
    "test_size=0.1\n",
    "val_size=0.1\n",
    "batch_size = 16    \n",
    "epochs=2 # For how many epochs to train\n",
    "\n",
    "\n",
    "FLAG_DEBUG = False\n",
    "FLAG_GENERATE_TABLE=True # If false: load a previously generated table\n",
    "FLAG_TRAIN=True # If false: just load a model, do not retrain\n",
    "FLAG_TRAIN_IN_PRELOAD=False #if false: train with lazy loading (see details in Training Modes section)\n",
    "\n",
    "label_names=['Human',\n",
    "             'Interaction frontal',\n",
    "             'Interaction lateral', \n",
    "             'Interaction vertical',\n",
    "             'Crowded', \n",
    "             'Drink',\n",
    "             'Curiosity', \n",
    "             'Queue',\n",
    "             'Low visibility', \n",
    "             'Nothing']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Math manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Vizualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "# Image processing\n",
    "import cv2\n",
    "\n",
    "# Utilities\n",
    "import os\n",
    "import random\n",
    "import gc\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.image import img_to_array, load_img\n",
    "from keras.utils import to_categorical\n",
    "import codecs, json \n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_pointer_table (list_of_videos, path_labels, plot=True, verbose=False):\n",
    "    pt_table = []\n",
    "    for filename in list_of_videos:\n",
    "        with open(filename) as json_file: file_labels = json.load(json_file)[1:]\n",
    "        i=1\n",
    "        name = re.search(str(path_labels + '(.+?).json'), filename).group(1)\n",
    "        if 'pointer_table' in name: continue\n",
    "        base_time = int(name) \n",
    "        while i<len(file_labels):\n",
    "            if file_labels[i]!=-1: pt_table.append([base_time, i, file_labels[i]])\n",
    "            i +=1\n",
    "    return pt_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def preprocess_frame(frame):\n",
    "#    frame = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY) # convert to greyscale\n",
    "#    frame = cv2.resize (frame, (img_width, img_height), interpolation=cv2.INTER_CUBIC) # rezize\n",
    "#    return frame\n",
    "\n",
    "def preprocess_frame(frame):\n",
    "    if type(frame) != int and len(frame.shape)>1:\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY) # convert to greyscale\n",
    "    frame = cv2.resize (frame, (img_width, img_height), interpolation=cv2.INTER_CUBIC) # rezize\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frame_from_pointer (path, video, frame, verbose=False):\n",
    "    if verbose: print ('In '+path+'/'+str(video)+'.mp4' + ', taking frame ' + str(frame))\n",
    "    cap = cv2.VideoCapture(path+'/'+str(video)+'.mp4')\n",
    "    if (cap.isOpened()== False):\n",
    "        print(\"Error opening video file\") \n",
    "        return -1\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, frame-1)\n",
    "    ret, frame = cap.read() # Capture next frame\n",
    "    if ret==True:\n",
    "        cap.release()\n",
    "        return frame\n",
    "    else:\n",
    "        print(\"Error opening frame\") \n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to delete the videos from the labels that they removed:\n",
    "\n",
    "for dirs in os.listdir(path_labels):\n",
    "    if dirs[:-5]+\".mp4\" not in os.listdir(path_videos):\n",
    "        print(dirs)\n",
    "        if len(dirs) == 15:\n",
    "            os.remove(path_labels+dirs)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_videos = [path_labels + i for i in sorted(os.listdir(path_labels))]\n",
    "pointer_table_path = path_labels + 'pointer_table.json'\n",
    "pointer_table_shuffled_path = path_labels + 'pointer_table_shuffled.json'\n",
    "if FLAG_DEBUG: print ('Number of files: ', len(list_of_videos))\n",
    "    \n",
    "if FLAG_GENERATE_TABLE:   \n",
    "    pt_table = generate_pointer_table (list_of_videos, path_labels)\n",
    "    json.dump(pt_table, codecs.open(pointer_table_path, 'w', encoding='utf-8'))\n",
    "    print ('Pointer table saved')\n",
    "    random.shuffle(pt_table)\n",
    "    json.dump(pt_table, codecs.open(pointer_table_shuffled_path, 'w', encoding='utf-8'))\n",
    "    print ('Shuffled pointer table saved')\n",
    "    \n",
    "else:\n",
    "    with open(pointer_table_shuffled_path) as json_file: pt_table = json.load(json_file)\n",
    "    #random.shuffle(pt_table)  #if you want to shuffle again\n",
    "    \n",
    "pt_table = np.array(pt_table)\n",
    "\n",
    "\n",
    "train_max_index = int(n*(1-test_size - val_size))\n",
    "val_max_index = int(train_max_index + n*val_size)\n",
    "test_max_index = int(val_max_index + n*test_size)\n",
    "\n",
    "pt_table_train = pt_table[0:train_max_index]\n",
    "pt_table_val = pt_table[train_max_index:val_max_index]\n",
    "pt_table_test = pt_table[val_max_index:test_max_index]\n",
    "\n",
    "if FLAG_DEBUG:\n",
    "    print ('Train index = ',0,':', train_max_index)\n",
    "    print ('Val index   = ', train_max_index,':', val_max_index)\n",
    "    print ('Test index  = ', val_max_index,':', test_max_index)\n",
    "\n",
    "\n",
    "#del list_of_videos, pt_table\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training modes\n",
    "To improve the training process, we developed two different modes of training that differ in the way the data is handled during the training: pre-loading the images or loading just-in-time. \n",
    "\n",
    "The **pre-loaded mode** loads the images into the computer's temporary memory only at the beginning of the training phase. This allows faster training; nevertheless, it was not possible to load more than 40k images at the same time without available hardware.\n",
    "\n",
    "The **just-in-time loading** (also designated in the documentation as lazy loading) retrieves the images from disk every time they are required in the training phase. This allows training with the entire dataset, no matter how big it is, but has the drawback that the same image had to be loaded several times (for instance: to train 10 epochs is necessary to load the same image 10 times).\n",
    "\n",
    "To change the training mode is enough to change the varible FLAG_TRAIN_IN_PRELOAD value. To train the network presented in this work, we used the just-in-time loading mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from albumentations import Compose\n",
    "import albumentations as A\n",
    "import random\n",
    "\n",
    "augmentation_train = A.Compose([\n",
    "    A.RandomContrast(limit=0.3, p=0.5),\n",
    "    A.RandomGamma(gamma_limit=(70, 130), p=0.5),\n",
    "    A.RandomBrightness(limit=0.6, p=0.5),\n",
    "    A.ShiftScaleRotate(\n",
    "        shift_limit=0.05, \n",
    "        scale_limit=0.05, \n",
    "        rotate_limit=10, \n",
    "        border_mode=cv2.BORDER_CONSTANT, \n",
    "        p=0.5), \n",
    "    A.ToFloat(max_value=255),\n",
    "])\n",
    "\n",
    "augmentation_test = A.Compose([\n",
    "    A.ToFloat(max_value=255)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Preload import \n",
    "# require more RAM, but train fast\n",
    "# verbose:   0=quiet, 1=inline output, 2=save figs\n",
    "def preload_import (pt_table, X_path, verbose=1):\n",
    "    X = []\n",
    "    y = []\n",
    "    for pointer in pt_table:\n",
    "        #print ('.')\n",
    "        frame = frame_from_pointer(path=X_path, video=pointer[0], frame=pointer[1])\n",
    "        frame = preprocess_frame(frame)\n",
    "        X.append(frame)\n",
    "        y.append(to_categorical(pointer[2], num_classes=10))\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)  \n",
    "    if verbose>=1:\n",
    "        print('------------------------')\n",
    "        print('Some random pics:')\n",
    "        plt.figure(figsize=(100,100))\n",
    "        cols = 4\n",
    "        rows = 4\n",
    "        for c in range(cols):\n",
    "            for r in range(rows):\n",
    "                plt.subplot(rows, cols, c + cols*r + 1)\n",
    "                plt.imshow(X[c + cols*r])\n",
    "                plt.title(label_names[np.argmax(y[c + cols*r])], fontsize=102)\n",
    "                \n",
    "                plt.axis('off')\n",
    "        if verbose>1: plt.savefig('sample_randoms.png')\n",
    "            \n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if FLAG_TRAIN_IN_PRELOAD:\n",
    "    X_train, y_train = preload_import (pt_table_train, X_path=path_videos, verbose=1)\n",
    "    print('Train dataset loaded')\n",
    "    X_val, y_val = preload_import (pt_table_val, X_path=path_videos, verbose=1)\n",
    "    print('Val dataset loaded')    \n",
    "    print('-- Split report (np shapes) --' + \n",
    "         '\\nTrain X      : ' + str(X_train.shape) + \n",
    "         '\\nTrain y      : ' + str(y_train.shape) + \n",
    "         '\\nValidation X : ' + str(X_val.shape) + \n",
    "         '\\nValidation y : ' + str(y_val.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_generator_preloaded (X_train, y_train, batch_size, augmentation): \n",
    "    indices = np.arange(len(X_train)) \n",
    "    while True:\n",
    "        batch_indices = np.random.choice(indices, batch_size, replace=False)\n",
    "        batch_X = []\n",
    "        batch_y = []\n",
    "        \n",
    "        for i in batch_indices:\n",
    "            frame = X_train[i]\n",
    "            frame = augmentation(image=frame)['image']\n",
    "            frame = frame.reshape(frame.shape[0], frame.shape[1], img_channels)\n",
    "            batch_X.append(frame)\n",
    "            batch_y.append(y_train[i])\n",
    "            \n",
    "        # Return a tuple of (input,output) to feed the network   \n",
    "        batch_X = np.array(batch_X)\n",
    "        batch_y = np.array(batch_y)\n",
    "        yield(batch_X, batch_y)\n",
    "\n",
    "if FLAG_TRAIN_IN_PRELOAD:\n",
    "    #get the length of the train and validation data\n",
    "    ntrain = len(X_train)\n",
    "    nval = len(X_val)\n",
    "\n",
    "    train_generator = image_generator_preloaded (X_train, y_train, batch_size=batch_size, augmentation=augmentation_train)\n",
    "    val_generator = image_generator_preloaded (X_train, y_train, batch_size=batch_size, augmentation=augmentation_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_generator_lazy (pt_table, batch_size, augmentation):\n",
    "    while True:          # Select files (paths/indices) for the batch\n",
    "        pointer_batch = pt_table[np.random.choice(pt_table.shape[0], batch_size, replace=False), :]\n",
    "        batch_X = []\n",
    "        batch_y = []\n",
    "        \n",
    "        for pointer in pointer_batch:\n",
    "            frame = frame_from_pointer(path=path_videos, video=pointer[0], frame=pointer[1])\n",
    "            #print(type(frame))\n",
    "            #if type(frame) != int: print(frame.shape)\n",
    "            frame = preprocess_frame(frame)\n",
    "            frame = frame.astype(np.float32) # MT added \n",
    "            frame = augmentation(image=frame)['image']\n",
    "            frame = frame.reshape(frame.shape[0], frame.shape[1], img_channels)\n",
    "            label = to_categorical(pointer[2], num_classes=10)\n",
    "        \n",
    "            batch_X.append(frame)\n",
    "            batch_y.append(label)\n",
    "             \n",
    "        # Return a tuple of (input,output) to feed the network          \n",
    "        batch_X = np.array(batch_X)\n",
    "        batch_y = np.array(batch_y)\n",
    "        yield(batch_X, batch_y)\n",
    "\n",
    "if not FLAG_TRAIN_IN_PRELOAD:\n",
    "    #get the length of the train and validation data\n",
    "    ntrain = len(pt_table_train)\n",
    "    nval = len(pt_table_val)\n",
    "\n",
    "    train_generator = image_generator_lazy (pt_table_train, batch_size=batch_size, augmentation=augmentation_train)\n",
    "    val_generator = image_generator_lazy (pt_table_val, batch_size=batch_size, augmentation=augmentation_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Visualizing one batch\n",
    "if FLAG_DEBUG:\n",
    "    batch_X, batch_y = next(train_generator)\n",
    "    print(batch_X.shape)\n",
    "    print(batch_y.shape)\n",
    "\n",
    "    plt.figure(figsize=(100,100))\n",
    "    cols = 4\n",
    "    rows = 4\n",
    "    for c in range(cols):\n",
    "        for r in range(rows):\n",
    "            plt.subplot(rows, cols, c + cols*r + 1)\n",
    "            img = batch_X[c + cols*r].reshape(batch_X[c + cols*r].shape[0], batch_X[c + cols*r].shape[1])\n",
    "            print ('Frame stats: ', img.mean(), ' - ', img.std())\n",
    "            plt.imshow(img)\n",
    "            plt.title(label_names[np.argmax(batch_y[c + cols*r])], fontsize=102)\n",
    "            plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model definition and training\n",
    "* That architecture is based on VGGnet architecture, with a few modifications (like dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import optimizers\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "\n",
    "#utils\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "\n",
    "# Models\n",
    "from keras import applications\n",
    "from keras.optimizers import SGD, Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(img_height, img_width, img_channels)),\n",
    "    MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
    "\n",
    "    Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
    "\n",
    "    Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
    "\n",
    "\n",
    "    Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
    "\n",
    "    Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
    "\n",
    "\n",
    "    Conv2D(512, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
    "\n",
    "    Conv2D(512, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "model.compile(loss=keras.losses.categorical_crossentropy, optimizer='adam', metrics=['accuracy']) \n",
    "    \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = load_model(model_stable_path) # load last stable model (can be commented to train from scrach)\n",
    "initial_epoch=0 # MT added\n",
    "    \n",
    "if FLAG_TRAIN: \n",
    "    callback_es = EarlyStopping(monitor='val_acc', mode='max', verbose=1, patience=20)\n",
    "    callback_cp = ModelCheckpoint(model_save_path, monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
    "\n",
    "    history = model.fit_generator(train_generator,\n",
    "                                  steps_per_epoch=ntrain // batch_size,\n",
    "                                  epochs=initial_epoch+epochs,\n",
    "                                  initial_epoch=initial_epoch,\n",
    "                                  validation_data=val_generator,\n",
    "                                  validation_steps=nval // batch_size,\n",
    "                                  verbose=0, \n",
    "                                  callbacks=[TQDMNotebookCallback(), callback_es, callback_cp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "#Train and validation acc\n",
    "plt.grid(True)\n",
    "plt.plot(epochs, acc, 'b', label='Training accurarcy')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation accurarcy')\n",
    "plt.title('Training and Validation accurarcy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "\n",
    "#Train and validation loss\n",
    "plt.grid(True)\n",
    "plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and Validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if FLAG_TRAIN:\n",
    "    model = load_model(model_save_path) # load the best model saved in training phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# The test should be done with pre loading, so I will take directly from the generator \n",
    "test_generator = image_generator_lazy (pt_table_test, batch_size=batch_size, augmentation=augmentation_test)\n",
    "\n",
    "X_test = []\n",
    "y_test = []\n",
    "predictions = []\n",
    "for i in range(0, int(len(pt_table_test)/batch_size)):\n",
    "    X_batch, y_batch = next(test_generator)\n",
    "    predictions_batch = model.predict_on_batch(X_batch)\n",
    "    X_test.extend(X_batch)\n",
    "    y_test.extend(y_batch)\n",
    "    predictions.extend(predictions_batch)\n",
    "\n",
    "X_test = np.array (X_test)\n",
    "y_test = np.array (y_test)\n",
    "predictions = np.array (predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, acc = model.evaluate(X_test, y_test)\n",
    "print('Test acc:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Brief: evaluate the 'accuracy' as considering a hit if the true label is in one of the three most confident predictions\n",
    "# Return: acc\n",
    "def evaluate_minority_acc (y, y_hat):\n",
    "    acc = 0\n",
    "    for i in range(0, len(y), 1):\n",
    "        pred_array = []\n",
    "        pred_array.append(np.where(y_hat[i] == sorted(y_hat[i])[-1])[0][0])\n",
    "        pred_array.append(np.where(y_hat[i] == sorted(y_hat[i])[-2])[0][0])\n",
    "        pred_array.append(np.where(y_hat[i] == sorted(y_hat[i])[-3])[0][0])\n",
    "        if np.argmax(y[i]) in pred_array: acc += 1\n",
    "    return acc/len (y)\n",
    "    \n",
    "    \n",
    "evaluate_minority_acc(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Brief: plot the image with the predicted label, confidence and real label\n",
    "def plot_image(i, prediction, true_label, img):\n",
    "    plt.grid(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "    plt.imshow(img.reshape(img.shape[0], img.shape[1]))\n",
    "\n",
    "    if np.argmax(prediction) == np.argmax(true_label):\n",
    "        color = 'blue'\n",
    "    else:\n",
    "        color = 'red'\n",
    "\n",
    "    plt.xlabel(\"{}) {}, {:2.0f}% \\n({})\".format(\n",
    "        i,\n",
    "        label_names[np.argmax(prediction)],\n",
    "        100*np.max(prediction),\n",
    "        label_names[np.argmax(true_label)]), color=color)\n",
    "\n",
    "# Brief: plot a bar graph with the probability of each predicted class\n",
    "def plot_value_array(prediction, true_label):\n",
    "    plt.grid(False)\n",
    "    plt.xticks(range(10))\n",
    "    thisplot = plt.bar(range(10), prediction, color=\"#777777\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the first X test images, their predicted labels, and the true labels.\n",
    "# Color correct predictions in blue and incorrect predictions in red.\n",
    "if FLAG_DEBUG:\n",
    "    num_rows = 160\n",
    "    num_cols = 1\n",
    "    num_images = num_rows*num_cols\n",
    "    plt.figure(figsize=(7, 4*num_rows))\n",
    "    for i in range(num_images):\n",
    "        plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
    "        plot_image(i, predictions[i], y_test[i], X_test[i])\n",
    "        plt.subplot(num_rows, 2*num_cols, 2*i+2)\n",
    "        plot_value_array(predictions[i],  y_test[i])\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_cm(y_true, y_pred, figsize=(10,10)):\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=np.unique(y_true))\n",
    "    cm_sum = np.sum(cm, axis=1, keepdims=True)\n",
    "    cm_perc = cm / cm_sum.astype(float) * 100\n",
    "    annot = np.empty_like(cm).astype(str)\n",
    "    nrows, ncols = cm.shape\n",
    "    for i in range(nrows):\n",
    "        for j in range(ncols):\n",
    "            c = cm[i, j]\n",
    "            p = cm_perc[i, j]\n",
    "            if i == j:\n",
    "                s = cm_sum[i]\n",
    "                annot[i, j] = '%.1f%%\\n%d/%d' % (p, c, s)\n",
    "            elif c == 0:\n",
    "                annot[i, j] = ''\n",
    "            else:\n",
    "                annot[i, j] = '%.1f%%\\n%d' % (p, c)\n",
    "    cm = pd.DataFrame(cm, index=np.unique(y_true), columns=np.unique(y_true))\n",
    "    cm.index.name = 'Actual'\n",
    "    cm.columns.name = 'Predicted'\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    sns.heatmap(cm, cmap= \"YlGnBu\", annot=annot, fmt='', ax=ax, linewidths=.5)\n",
    "\n",
    "plot_cm(np.array([np.argmax(xi) for xi in y_test]), np.array([np.argmax(xi) for xi in predictions]))\n",
    "_n=0\n",
    "for i in label_names:\n",
    "    print('Class ' + str(_n) + ': ' + i)\n",
    "    _n+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics\n",
    "print(metrics.classification_report(np.array([np.argmax(xi) for xi in y_test]), np.array([np.argmax(xi) for xi in predictions]), target_names=label_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "License: Creative Commons 4.0 Attribute"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras-CS762-env",
   "language": "python",
   "name": "keras-cs762-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
